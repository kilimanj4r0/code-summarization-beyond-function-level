{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of summaries (true, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-28 13:27:45.696000: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-28 13:27:45.749800: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-28 13:27:45.749859: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-28 13:27:45.751371: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-28 13:27:45.761520: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-28 13:27:46.886155: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from enum import Enum\n",
    "from evaluate import load  # https://huggingface.co/evaluate-metric\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch.nn.functional as F\n",
    "from sentence_transformers import util\n",
    "from huggingface_hub import configure_http_backend\n",
    "def backend_factory() -> requests.Session:\n",
    "    session = requests.Session()\n",
    "    session.proxies = {\"https\": \"http://34e9515e90e14e90:9d35c556ec546bc6@135.181.81.30:3128\"}\n",
    "    # session.verify = False\n",
    "    return session\n",
    "configure_http_backend(backend_factory=backend_factory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "side_model_dir = Path(\"../models/side\")\n",
    "side_tokenizer = AutoTokenizer.from_pretrained(side_model_dir)\n",
    "side_model = AutoModel.from_pretrained(side_model_dir).to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"../data\")\n",
    "\n",
    "PREDICTED_DATA_DIR = DATA_DIR / \"predicted\"\n",
    "model_names = [\n",
    "    \"SEBIS/code_trans_t5_large_source_code_summarization_python_multitask_finetune\",\n",
    "    \"SEBIS/code_trans_t5_large_code_documentation_generation_python_multitask_finetune\",\n",
    "    \"Salesforce/codet5-base-multi-sum\",\n",
    "    \"Paul-B98/codet5p_220m_py_sum\",\n",
    "    \"lintang/pile-t5-large-codexglue\",\n",
    "    \"deepseek-ai/deepseek-coder-6.7b-instruct\",\n",
    "    \"gradientai/Llama-3-8B-Instruct-Gradient-1048k\"\n",
    "]\n",
    "MODEL_NAME = model_names[-1]\n",
    "MODEL_RESULTS_DIR = PREDICTED_DATA_DIR / MODEL_NAME.split(\"/\")[-1]\n",
    "\n",
    "LEVEL = 'method'\n",
    "DATASET = 'mce'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics(Enum):\n",
    "    ROUGE = 'ROUGE-L'\n",
    "    BLEU = 'BLEU-4'\n",
    "    METEOR = 'METEOR'\n",
    "    BERTScore = 'BERTScore'\n",
    "    BLEURT = 'BLEURT'\n",
    "    SIDE_TRUE = 'SIDE_true'\n",
    "    SIDE_PRED = 'SIDE_pred'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for model_dir in PREDICTED_DATA_DIR.glob('*'):\n",
    "    for file_path in model_dir.glob('*eval.json'):\n",
    "        with file_path.open('r') as file:\n",
    "            data = json.load(file)\n",
    "            if 'mcsn' in str(file_path):\n",
    "                for key in data.keys():\n",
    "                    sub_data = data[key]\n",
    "                    sub_data['Name'] = '/'.join(str(file_path).split('/')[-2:]) + '/' + key\n",
    "                    dfs.append(pd.DataFrame([sub_data]))\n",
    "            else:\n",
    "                data['Name'] = '/'.join(str(file_path).split('/')[-2:])\n",
    "                dfs.append(pd.DataFrame([data]))\n",
    "\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "combined_df.set_index('Name', inplace=True)\n",
    "markdown_table = combined_df.to_markdown()\n",
    "print(markdown_table)\n",
    "\n",
    "combined_df.to_csv(Path('../data/predicted/results.csv'), sep=',', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/predicted/code_trans_t5_large_source_code_summarization_python_multitask_finetune/method-level-mcsn-pred.jsonl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_name</th>\n",
       "      <th>method_name</th>\n",
       "      <th>method_code</th>\n",
       "      <th>method_summary</th>\n",
       "      <th>pred_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apache/airflow</td>\n",
       "      <td>HttpHook.run</td>\n",
       "      <td>def run(self, endpoint, data=None, headers=Non...</td>\n",
       "      <td>Performs the request</td>\n",
       "      <td>Sending a HTTP request to a Pylons service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apache/airflow</td>\n",
       "      <td>HttpHook.check_response</td>\n",
       "      <td>def check_response(self, response):\\n        t...</td>\n",
       "      <td>Checks the status code and raise an AirflowExc...</td>\n",
       "      <td>Raise AirflowException on non 200 status codes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apache/airflow</td>\n",
       "      <td>HttpHook.run_and_check</td>\n",
       "      <td>def run_and_check(self, session, prepped_reque...</td>\n",
       "      <td>Grabs extra options like timeout and actually ...</td>\n",
       "      <td>Deploying a service in Tenacity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apache/airflow</td>\n",
       "      <td>create_session</td>\n",
       "      <td>def create_session():\\n    session = settings....</td>\n",
       "      <td>Contextmanager that will create and teardown a...</td>\n",
       "      <td>A context manager for SQLAlchemy with a simple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apache/airflow</td>\n",
       "      <td>resetdb</td>\n",
       "      <td>def resetdb():\\n    from airflow import models...</td>\n",
       "      <td>Clear out the database</td>\n",
       "      <td>Drop tables that exist in the database</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        repo_name              method_name  \\\n",
       "0  apache/airflow             HttpHook.run   \n",
       "1  apache/airflow  HttpHook.check_response   \n",
       "2  apache/airflow   HttpHook.run_and_check   \n",
       "3  apache/airflow           create_session   \n",
       "4  apache/airflow                  resetdb   \n",
       "\n",
       "                                         method_code  \\\n",
       "0  def run(self, endpoint, data=None, headers=Non...   \n",
       "1  def check_response(self, response):\\n        t...   \n",
       "2  def run_and_check(self, session, prepped_reque...   \n",
       "3  def create_session():\\n    session = settings....   \n",
       "4  def resetdb():\\n    from airflow import models...   \n",
       "\n",
       "                                      method_summary  \\\n",
       "0                               Performs the request   \n",
       "1  Checks the status code and raise an AirflowExc...   \n",
       "2  Grabs extra options like timeout and actually ...   \n",
       "3  Contextmanager that will create and teardown a...   \n",
       "4                             Clear out the database   \n",
       "\n",
       "                                        pred_summary  \n",
       "0         Sending a HTTP request to a Pylons service  \n",
       "1     Raise AirflowException on non 200 status codes  \n",
       "2                    Deploying a service in Tenacity  \n",
       "3  A context manager for SQLAlchemy with a simple...  \n",
       "4             Drop tables that exist in the database  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = MODEL_RESULTS_DIR / f\"{LEVEL}-level-{DATASET}-pred.jsonl\"\n",
    "print(file_path)\n",
    "df = pd.read_json(file_path, lines=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/predicted/Llama-3-8B-Instruct-Gradient-1048k/method-level-sample-mce-few-shot-0-pred.jsonl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>class_id</th>\n",
       "      <th>class_code</th>\n",
       "      <th>skeleton</th>\n",
       "      <th>method_code</th>\n",
       "      <th>method_summary</th>\n",
       "      <th>pred_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ClassEval_0_sum</td>\n",
       "      <td>import logging\\nimport datetime\\n\\n\\nclass Acc...</td>\n",
       "      <td>import logging\\nimport datetime\\n\\nclass Acces...</td>\n",
       "      <td>def filter(self, request):\\n        request_ur...</td>\n",
       "      <td>Filter the incoming request based on certain r...</td>\n",
       "      <td>The `filter` method takes in a request object ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ClassEval_0_sum</td>\n",
       "      <td>import logging\\nimport datetime\\n\\n\\nclass Acc...</td>\n",
       "      <td>import logging\\nimport datetime\\n\\nclass Acces...</td>\n",
       "      <td>def is_start_with(self, request_uri):\\n       ...</td>\n",
       "      <td>Check if the request URI starts with certain p...</td>\n",
       "      <td>The `is_start_with` method takes a `request_ur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ClassEval_0_sum</td>\n",
       "      <td>import logging\\nimport datetime\\n\\n\\nclass Acc...</td>\n",
       "      <td>import logging\\nimport datetime\\n\\nclass Acces...</td>\n",
       "      <td>def get_jwt_user(self, request):\\n        toke...</td>\n",
       "      <td>Get the user information from the JWT token in...</td>\n",
       "      <td>The code retrieves the user from the JWT token...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ClassEval_0_sum</td>\n",
       "      <td>import logging\\nimport datetime\\n\\n\\nclass Acc...</td>\n",
       "      <td>import logging\\nimport datetime\\n\\nclass Acces...</td>\n",
       "      <td>def set_current_user_info_and_log(self, user):...</td>\n",
       "      <td>Set the current user information and log the a...</td>\n",
       "      <td>The code sets the current user information and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ClassEval_1_sum</td>\n",
       "      <td>import math\\n\\n\\nclass AreaCalculator:\\n    \"\"...</td>\n",
       "      <td>import math\\nclass AreaCalculator:\\n    \"\"\"\\n ...</td>\n",
       "      <td>def calculate_circle_area(self):\\n        retu...</td>\n",
       "      <td>calculate the area of circle based on self.radius</td>\n",
       "      <td>The Python code defines a method called `calcu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index         class_id                                         class_code  \\\n",
       "0      0  ClassEval_0_sum  import logging\\nimport datetime\\n\\n\\nclass Acc...   \n",
       "1      1  ClassEval_0_sum  import logging\\nimport datetime\\n\\n\\nclass Acc...   \n",
       "2      2  ClassEval_0_sum  import logging\\nimport datetime\\n\\n\\nclass Acc...   \n",
       "3      3  ClassEval_0_sum  import logging\\nimport datetime\\n\\n\\nclass Acc...   \n",
       "4      4  ClassEval_1_sum  import math\\n\\n\\nclass AreaCalculator:\\n    \"\"...   \n",
       "\n",
       "                                            skeleton  \\\n",
       "0  import logging\\nimport datetime\\n\\nclass Acces...   \n",
       "1  import logging\\nimport datetime\\n\\nclass Acces...   \n",
       "2  import logging\\nimport datetime\\n\\nclass Acces...   \n",
       "3  import logging\\nimport datetime\\n\\nclass Acces...   \n",
       "4  import math\\nclass AreaCalculator:\\n    \"\"\"\\n ...   \n",
       "\n",
       "                                         method_code  \\\n",
       "0  def filter(self, request):\\n        request_ur...   \n",
       "1  def is_start_with(self, request_uri):\\n       ...   \n",
       "2  def get_jwt_user(self, request):\\n        toke...   \n",
       "3  def set_current_user_info_and_log(self, user):...   \n",
       "4  def calculate_circle_area(self):\\n        retu...   \n",
       "\n",
       "                                      method_summary  \\\n",
       "0  Filter the incoming request based on certain r...   \n",
       "1  Check if the request URI starts with certain p...   \n",
       "2  Get the user information from the JWT token in...   \n",
       "3  Set the current user information and log the a...   \n",
       "4  calculate the area of circle based on self.radius   \n",
       "\n",
       "                                        pred_summary  \n",
       "0  The `filter` method takes in a request object ...  \n",
       "1  The `is_start_with` method takes a `request_ur...  \n",
       "2  The code retrieves the user from the JWT token...  \n",
       "3  The code sets the current user information and...  \n",
       "4  The Python code defines a method called `calcu...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = MODEL_RESULTS_DIR / f\"{LEVEL}-level-sample-{DATASET}-few-shot-0-pred.jsonl\"\n",
    "print(file_path)\n",
    "df = pd.read_json(file_path, lines=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_column_name = 'method_summary'\n",
    "pred_column_name = 'pred_summary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_summaries = df[true_column_name].to_list()\n",
    "pred_summaries = df[pred_column_name].to_list()\n",
    "assert len(true_summaries) == len(pred_summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in Metrics:\n",
    "    df[metric.value] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_side(tokenizer, model, code, summary):\n",
    "    def _mean_pooling(model_output, attention_mask):\n",
    "        token_embeddings = model_output[0]\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    \n",
    "    pair = [code, summary]\n",
    "    encoded_input = tokenizer(pair, padding=True, truncation=True, return_tensors='pt').to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "\n",
    "    sentence_embeddings = _mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "    sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "    sim = util.pytorch_cos_sim(sentence_embeddings[0], sentence_embeddings[1]).item()\n",
    "    return sim\n",
    "\n",
    "def compute_side_partial(args):\n",
    "    return compute_side(side_tokenizer, side_model, *args)\n",
    "\n",
    "side_model_dir = Path(\"../models/side\")\n",
    "side_tokenizer = AutoTokenizer.from_pretrained(side_model_dir)\n",
    "side_model = AutoModel.from_pretrained(side_model_dir).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading checkpoint /root/.cache/huggingface/metrics/bleurt/BLEURT-20/downloads/extracted/cd1c38739d180ae53192201859a058307621534b704c20700072eca17d748c58/BLEURT-20.\n",
      "INFO:tensorflow:Config file found, reading.\n",
      "INFO:tensorflow:Will load checkpoint BLEURT-20\n",
      "INFO:tensorflow:Loads full paths and checks that files exists.\n",
      "INFO:tensorflow:... name:BLEURT-20\n",
      "INFO:tensorflow:... bert_config_file:bert_config.json\n",
      "INFO:tensorflow:... max_seq_length:512\n",
      "INFO:tensorflow:... vocab_file:None\n",
      "INFO:tensorflow:... do_lower_case:None\n",
      "INFO:tensorflow:... sp_model:sent_piece\n",
      "INFO:tensorflow:... dynamic_seq_length:True\n",
      "INFO:tensorflow:Creating BLEURT scorer.\n",
      "INFO:tensorflow:Creating SentencePiece tokenizer.\n",
      "INFO:tensorflow:Creating SentencePiece tokenizer.\n",
      "INFO:tensorflow:Will load model: /root/.cache/huggingface/metrics/bleurt/BLEURT-20/downloads/extracted/cd1c38739d180ae53192201859a058307621534b704c20700072eca17d748c58/BLEURT-20/sent_piece.model.\n",
      "INFO:tensorflow:SentencePiece tokenizer created.\n",
      "INFO:tensorflow:Creating Eager Mode predictor.\n",
      "INFO:tensorflow:Loading model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-12 00:38:45.375621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11779 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:17:00.0, compute capability: 8.0\n",
      "2024-05-12 00:38:45.376919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 76523 MB memory:  -> device: 1, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:31:00.0, compute capability: 8.0\n",
      "2024-05-12 00:38:45.378074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 76523 MB memory:  -> device: 2, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:b1:00.0, compute capability: 8.0\n",
      "2024-05-12 00:38:45.379219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 75813 MB memory:  -> device: 3, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:ca:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:BLEURT initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:BLEURT initialized.\n"
     ]
    }
   ],
   "source": [
    "bleurt = load('bleurt', 'BLEURT-20', module_type=\"metric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertscore = load('bertscore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "bleu = load('bleu')\n",
    "rouge = load('rouge')\n",
    "meteor = load('meteor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:18<00:00, 21.39it/s]\n",
      "100%|██████████| 400/400 [00:27<00:00, 14.71it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "df[Metrics.SIDE_TRUE.value] = df[['method_code', true_column_name]].progress_apply(compute_side_partial, axis=1)\n",
    "df[Metrics.SIDE_PRED.value] = df[['method_code', pred_column_name]].progress_apply(compute_side_partial, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleurt_res = bleurt.compute(predictions=pred_summaries, references=true_summaries)\n",
    "df[Metrics.BLEURT.value] = bleurt_res['scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertscore_res = bertscore.compute(\n",
    "    predictions=pred_summaries,\n",
    "    references=true_summaries,\n",
    "    model_type='microsoft/deberta-xlarge-mnli',\n",
    "    device=torch.device(\"cuda:1\")\n",
    ")\n",
    "df[Metrics.BERTScore.value] = bertscore_res['f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:41<00:00,  9.54it/s]\n"
     ]
    }
   ],
   "source": [
    "for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    true_summary = row[true_column_name]\n",
    "    pred_summary = row[pred_column_name]\n",
    "\n",
    "    bleu_res = bleu.compute(predictions=[pred_summary], references=[[true_summary]])\n",
    "    rouge_res = rouge.compute(predictions=[pred_summary], references=[true_summary])\n",
    "    meteor_res = meteor.compute(predictions=[pred_summary], references=[true_summary])\n",
    "\n",
    "    df.at[index, Metrics.ROUGE.value] = rouge_res['rougeL']\n",
    "    df.at[index, Metrics.BLEU.value] = bleu_res['bleu']\n",
    "    df.at[index, Metrics.METEOR.value] = meteor_res['meteor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>class_id</th>\n",
       "      <th>class_code</th>\n",
       "      <th>skeleton</th>\n",
       "      <th>method_code</th>\n",
       "      <th>method_summary</th>\n",
       "      <th>pred_summary</th>\n",
       "      <th>ROUGE-L</th>\n",
       "      <th>BLEU-4</th>\n",
       "      <th>METEOR</th>\n",
       "      <th>BERTScore</th>\n",
       "      <th>BLEURT</th>\n",
       "      <th>SIDE_true</th>\n",
       "      <th>SIDE_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ClassEval_0_sum</td>\n",
       "      <td>import logging\\nimport datetime\\n\\n\\nclass Acc...</td>\n",
       "      <td>import logging\\nimport datetime\\n\\nclass Acces...</td>\n",
       "      <td>def filter(self, request):\\n        request_ur...</td>\n",
       "      <td>Filter the incoming request based on certain r...</td>\n",
       "      <td>The `filter` method takes in a request object ...</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.541831</td>\n",
       "      <td>0.500012</td>\n",
       "      <td>0.101102</td>\n",
       "      <td>0.769831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index         class_id                                         class_code  \\\n",
       "0      0  ClassEval_0_sum  import logging\\nimport datetime\\n\\n\\nclass Acc...   \n",
       "\n",
       "                                            skeleton  \\\n",
       "0  import logging\\nimport datetime\\n\\nclass Acces...   \n",
       "\n",
       "                                         method_code  \\\n",
       "0  def filter(self, request):\\n        request_ur...   \n",
       "\n",
       "                                      method_summary  \\\n",
       "0  Filter the incoming request based on certain r...   \n",
       "\n",
       "                                        pred_summary   ROUGE-L BLEU-4  \\\n",
       "0  The `filter` method takes in a request object ...  0.106383    0.0   \n",
       "\n",
       "     METEOR  BERTScore    BLEURT  SIDE_true  SIDE_pred  \n",
       "0  0.153846   0.541831  0.500012   0.101102   0.769831  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "df.to_json(MODEL_RESULTS_DIR / f\"{LEVEL}-level-{DATASET}-pred-metrics.jsonl\", orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "df.to_json(MODEL_RESULTS_DIR / f\"{LEVEL}-level-sample-{DATASET}-few-shot-0-pred-metrics.jsonl\", orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET != \"mcsn\":\n",
    "    total_avg_metrics = {metric.value: df[metric.value].mean() for metric in Metrics}\n",
    "else:\n",
    "    total_avg_metrics = {\n",
    "        \"total\": {metric.value: df[metric.value].mean() for metric in Metrics}\n",
    "    }\n",
    "    repo_avg_metrics = {\n",
    "        repo_name: {\n",
    "            metric.value: df.loc[df[\"repo_name\"] == repo_name, metric.value].mean()\n",
    "            for metric in Metrics\n",
    "        }\n",
    "        for repo_name in df[\"repo_name\"].unique()\n",
    "    }\n",
    "    total_avg_metrics.update(repo_avg_metrics)\n",
    "\n",
    "\n",
    "eval_output_file_path = MODEL_RESULTS_DIR / f\"{LEVEL}-level-sample-{DATASET}-few-shot-0-eval.json\"\n",
    "with open(eval_output_file_path, \"w\") as file:\n",
    "    json.dump(total_avg_metrics, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vladimir-langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
